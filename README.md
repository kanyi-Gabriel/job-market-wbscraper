# Remote Job Market Analysis (Web Scraping + EDA)

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-Automation-brightgreen?logo=selenium&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-purple?logo=pandas)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualization-orange?logo=plotly&logoColor=white)

---

##  Project Overview
This project demonstrates **end-to-end web scraping, data cleaning, and analysis** of remote job postings.  
We collected live job postings from **[RemoteOK](https://remoteok.com/)** using Selenium, structured the dataset, and performed **Exploratory Data Analysis (EDA)** to extract actionable insights.


---

##  Objectives
- Scrape **job postings** (title, company, skills, salary, location, posting date).  
- Clean and normalize messy text fields (skills, salaries, locations).  
- Flatten skills into analyzable format.  
- Perform **EDA with visualizations**:
  - Most in-demand skills  
  - Top hiring companies  
  - Job location breakdown  
  - Salary distribution  
  - Job postings trend over time  

---


## ðŸ“‚ Project Structure

â”£ ðŸ“œ README.md

â”£ ðŸ“œ requirements.txt

â”£ ðŸ“‚ notebooks
â”ƒ â”— ðŸ““ web-scrap.ipynb

â”£ ðŸ“‚ data
â”ƒ â”— remoteok_jobs.csv

â”— ðŸ“‚ images
  â”£ top_skills.png
  â”£ salary_distribution.png
  â”— jobs_trend.png

  
---

## ðŸ“Š Key Insights
### ðŸ”¹ Top 20 Skills in Demand
![Top Skills](images/top_skills.jpg)

> Python, AWS, and SQL dominate the remote data science job market.

### ðŸ”¹ Salary Distribution
![Salary Distribution](images/salary_distribution.jpg)

> Most jobs fall between **$60kâ€“120k**, with some high-paying roles exceeding $150k.

### ðŸ”¹ Job Postings Over Time
![Jobs Trend](images/jobs_trend.jpg)

> Remote job postings show consistent demand, peaking in the last month.

---
 

##  Setup & Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/<kanyi-Gabriel>/job-market-wbscraper.git
   
2. Create a virtual environment
    ```bash

   conda create -- name environment_name
   conda activate environment_name
   pip install -r requirements.txt
    
3. To add the environment to jupyter notebook
    ```bash
    conda install -c anaconda ipykernel
    python -m ipykernel install --user--name = environment_name

